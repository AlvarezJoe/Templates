{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78759432",
   "metadata": {},
   "source": [
    "# <center>Hypothesis Testing<center/>\n",
    "## <center>T-Tests<center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1cb69c",
   "metadata": {},
   "source": [
    "The null hypothesis for a t-test is that there is no statistically significant difference between the means of two groups or samples. In other words, __the null hypothesis assumes that the population means for the two groups are equal__. The alternative hypothesis, on the other hand, assumes that there is a statistically significant difference between the means of the two groups.\n",
    "\n",
    "The null hypothesis for a one-sample t-test is that there is no statistically significant difference between the mean of a single sample and a known or hypothesized population mean.\n",
    "\n",
    "It is important to note that the null hypothesis is not necessarily true, but is assumed to be true unless there is sufficient evidence to reject it. A t-test is used to evaluate whether the sample data provides sufficient evidence to reject the null hypothesis in favor of the alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0d04f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-test statistic: -5.118697228488121\n",
      "p-value: 1.5349270535552999e-06\n"
     ]
    }
   ],
   "source": [
    "#t-test\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Generate two random samples of data\n",
    "sample1 = np.random.normal(loc=0, scale=1, size=50)\n",
    "sample2 = np.random.normal(loc=1, scale=1, size=50)\n",
    "\n",
    "# Perform t-test\n",
    "stat, p = ttest_ind(sample1, sample2)\n",
    "print(\"t-test statistic:\", stat)\n",
    "print(\"p-value:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213417c",
   "metadata": {},
   "source": [
    "### Assumptions:\n",
    "\n",
    "- Independence: The observations in each sample are independent of each other. That is, the values in one sample are not related to the values in the other sample.\n",
    "- Normality: The populations from which the samples are drawn are normally distributed. In practice, this assumption is not always necessary if the sample sizes are sufficiently large, as the Central Limit Theorem suggests that the sampling distribution of the mean will approach normality regardless of the underlying distribution of the population.\n",
    "- Homogeneity of variance: The variances of the populations from which the samples are drawn are equal. This assumption is important because it affects the standard error of the mean difference and, therefore, the t-test statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d52d39",
   "metadata": {},
   "source": [
    "Independence is typically assumed when conducting a t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c55985",
   "metadata": {},
   "source": [
    "Homogeneity can be test with a variablity test such as levene's test. __The null hypothesis in Levene's test is that the variances of the groups being compared are equal__. In other words, the null hypothesis assumes that the population variances for all groups are equal. \n",
    "\n",
    "Here's what that would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2587849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene's test statistic: 13.55213574231272\n",
      "p-value: 0.0003797042402190668\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import levene\n",
    "\n",
    "# Generate two random samples of data\n",
    "sample1 = np.random.normal(loc=0, scale=1, size=50)\n",
    "sample2 = np.random.normal(loc=1, scale=2, size=50)\n",
    "\n",
    "# Perform Levene's test to compare the variances of the two groups\n",
    "stat, p = levene(sample1, sample2)\n",
    "\n",
    "# Print the test statistic and p-value\n",
    "print(\"Levene's test statistic:\", stat)\n",
    "print(\"p-value:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e4d398",
   "metadata": {},
   "source": [
    "Normality is best tested with a Shapiro-Wilk test.\n",
    "\n",
    "__The null hypothesis of the Shapiro-Wilk test is that the data are drawn from a normally distributed population__.\n",
    "\n",
    "In other words, the test assumes that the sample data comes from a normally distributed population, and the test is used to determine whether the sample data provides enough evidence to reject this assumption. The alternative hypothesis, in this case, is that the data do not come from a normal distribution.\n",
    "\n",
    "If the p-value resulting from the Shapiro-Wilk test is less than the chosen significance level, it suggests that there is significant evidence to reject the null hypothesis, and conclude that the sample data does not come from a normal distribution. If the p-value is greater than the significance level, it suggests that there is not enough evidence to reject the null hypothesis, and the data can be assumed to come from a normal distribution.\n",
    "\n",
    "It is important to note that the Shapiro-Wilk test has some limitations and may not always be the most appropriate test for assessing normality, especially when the sample size is small or the distribution has heavy tails or skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966dd8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk test statistic for sample 1: 0.9843613505363464\n",
      "p-value for sample 1: 0.7438374161720276\n",
      "Shapiro-Wilk test statistic for sample 2: 0.9683470129966736\n",
      "p-value for sample 2: 0.198089137673378\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Generate two random samples of data\n",
    "sample1 = np.random.normal(loc=0, scale=1, size=50)\n",
    "sample2 = np.random.normal(loc=1, scale=1, size=50)\n",
    "\n",
    "# Perform Shapiro-Wilk test on sample 1\n",
    "stat, p = shapiro(sample1)\n",
    "print(\"Shapiro-Wilk test statistic for sample 1:\", stat)\n",
    "print(\"p-value for sample 1:\", p)\n",
    "\n",
    "# Perform Shapiro-Wilk test on sample 2\n",
    "stat, p = shapiro(sample2)\n",
    "print(\"Shapiro-Wilk test statistic for sample 2:\", stat)\n",
    "print(\"p-value for sample 2:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e944cd",
   "metadata": {},
   "source": [
    "### Special cases of t-testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d0032",
   "metadata": {},
   "source": [
    "__Power t-test__: A power t-test is a type of t-test that is used to determine the statistical power of a hypothesis test. It involves calculating the minimum sample size required to achieve a desired level of statistical power, given a specific effect size and significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f20ba93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size:  63.765611775409525\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.stats.power as power\n",
    "\n",
    "# Define the effect size, alpha level, and desired power\n",
    "effect_size = 0.5\n",
    "alpha = 0.05\n",
    "power_level = 0.8\n",
    "\n",
    "# Calculate the required sample size\n",
    "sample_size = power.tt_ind_solve_power(\n",
    "    effect_size=effect_size, alpha=alpha, power=power_level, ratio=1, alternative='two-sided')\n",
    "\n",
    "# Print the results\n",
    "print(\"Required sample size: \", sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea2ba2",
   "metadata": {},
   "source": [
    "__Proportions t-test__: A proportions t-test, also known as a z-test, is a type of statistical test that is used to compare the proportions of two categorical variables. It involves comparing the observed proportions of the two variables to the expected proportions under a null hypothesis, and calculating a test statistic and p-value to determine whether the difference between the observed and expected proportions is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ca3a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions z-test:\n",
      "z-statistic =  -2.886751345948129\n",
      "p-value =  0.003892417122778628\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.stats.proportion as prop\n",
    "\n",
    "# Define the number of successes and failures in two groups\n",
    "successes1 = 30\n",
    "failures1 = 70\n",
    "successes2 = 50\n",
    "failures2 = 50\n",
    "\n",
    "# Conduct a proportions z-test\n",
    "z_stat, p_val = prop.proportions_ztest(\n",
    "    count=[successes1, successes2], nobs=[successes1+failures1, successes2+failures2], alternative='two-sided')\n",
    "\n",
    "# Print the results\n",
    "print(\"Proportions z-test:\")\n",
    "print(\"z-statistic = \", z_stat)\n",
    "print(\"p-value = \", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3ff60",
   "metadata": {},
   "source": [
    "## <center>ANOVA<center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3b9fc8",
   "metadata": {},
   "source": [
    "ANOVA stands for Analysis of Variance, which is a statistical method used to compare the means of two or more groups. ANOVA tests whether the means of different groups are statistically significantly different from each other or not, by examining the variance between the groups and within the groups.\n",
    "\n",
    "ANOVA is typically used when comparing the means of more than two groups, and it can be used for both parametric and non-parametric data. There are different types of ANOVA, such as one-way ANOVA, two-way ANOVA, and repeated measures ANOVA, each of which has its own specific application.\n",
    "\n",
    "The basic idea of ANOVA is to compare the amount of variance in the data that can be attributed to the differences between groups (called the between-group variance) to the amount of variance that is due to the differences within groups (called the within-group variance). If the between-group variance is much larger than the within-group variance, then it suggests that the groups are significantly different from each other, and the null hypothesis of equal means can be rejected.\n",
    "\n",
    "__The null hypothesis in ANOVA is a statement that there is no significant difference between the means of the groups being compared__. Specifically, the null hypothesis for one-way ANOVA is that the population means of all groups are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcba2491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-value: 9.560975609756097\n",
      "p-value: 0.00328614384744518\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Group A': [85, 91, 76, 83, 89], \n",
    "                   'Group B': [75, 80, 82, 78, 81], \n",
    "                   'Group C': [90, 87, 92, 89, 94]})\n",
    "                   \n",
    "data = df.values.flatten()\n",
    "\n",
    "fvalue, pvalue = stats.f_oneway(df['Group A'], df['Group B'], df['Group C'])\n",
    "\n",
    "print('F-value:', fvalue)\n",
    "print('p-value:', pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8482b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sum_sq   df          F    PR(>F)\n",
      "Group       40.0  3.0  26.666667  0.004184\n",
      "Residual     2.0  4.0        NaN       NaN\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------\n",
      "     A      B      2.0 0.1458 -0.8785 4.8785  False\n",
      "     A      C      4.0 0.0164  1.1215 6.8785   True\n",
      "     A      D      6.0 0.0037  3.1215 8.8785   True\n",
      "     B      C      2.0 0.1458 -0.8785 4.8785  False\n",
      "     B      D      4.0 0.0164  1.1215 6.8785   True\n",
      "     C      D      2.0 0.1458 -0.8785 4.8785  False\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import pandas as pd\n",
    "\n",
    "# Create example data\n",
    "data = pd.DataFrame({'Group': ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D'],\n",
    "                     'Values': [1, 2, 3, 4, 5, 6, 7, 8]})\n",
    "\n",
    "# Perform ANOVA to test for differences between groups\n",
    "model = sm.formula.ols('Values ~ Group', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Perform Tukey test to compare all pairs of groups\n",
    "tukey_results = pairwise_tukeyhsd(data['Values'], data['Group'])\n",
    "\n",
    "print(anova_table)  # Print ANOVA table\n",
    "print(tukey_results)  # Print Tukey results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc105e4",
   "metadata": {},
   "source": [
    "## <center>Non-parametric testing<center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2509a6ec",
   "metadata": {},
   "source": [
    "Nonparametric testing is a statistical method used to make inferences about population parameters based on data that do not satisfy the assumptions of traditional parametric tests. Parametric tests assume that the data follows a specific probability distribution, usually the normal distribution, and that the parameters of that distribution are known or estimated from the data. Nonparametric tests, on the other hand, make fewer assumptions about the underlying distribution of the data and are therefore more robust to violations of assumptions such as normality or homoscedasticity.\n",
    "\n",
    "Nonparametric tests are often used when the data is ordinal or nominal, when the sample size is small, or when the data does not follow a normal distribution. Nonparametric tests are also useful when the research question focuses on differences in central tendency or variability rather than on specific numerical estimates of population parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4c1fdd",
   "metadata": {},
   "source": [
    "Here is a brief guide to some of the most common nonparametric tests:\n",
    "\n",
    "- Wilcoxon signed-rank test: Used to compare two related samples (e.g., pre-test and post-test scores) to determine whether there is a significant difference between them.\n",
    "\n",
    "- Mann-Whitney U test: Used to compare two independent samples to determine whether there is a significant difference between them.\n",
    "\n",
    "- Kruskal-Wallis test: Used to compare three or more independent samples to determine whether there is a significant difference between them.\n",
    "\n",
    "- Friedman test: Used to compare three or more related samples to determine whether there is a significant difference between them.\n",
    "\n",
    "- Chi-square test: Used to test the association between two categorical variables.\n",
    "\n",
    "- McNemar's test: Used to compare two related categorical variables to determine whether there is a significant difference between them.\n",
    "\n",
    "It's worth noting that this is not an exhaustive list, and there are many other nonparametric tests available depending on the research question and type of data. Additionally, it's important to consult the documentation of the specific test being used to determine the appropriate assumptions and test conditions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
